\begin{table}[H]
	\centering
	\renewcommand{\arraystretch}{1.4}
	\scalebox{0.9}{
	\begin{tabularx}{1.1\textwidth}{| X | r ? c | c | c | c ? c | c | c | c ? c | c | c | c |}
		\hline
		\rowcolor{tud9c}
		\multicolumn{14}{| c |}{\textcolor{white}{\textbf{Effects of data set size and class balance in the
		\caps{WordContent} task}}}
		\\ \hline
		\rowcolor{tud9c!70}
													&
													&
		\multicolumn{4}{ c ?}{\textbf{10k}} 			&
		\multicolumn{4}{ c ?}{\textbf{30k}} 			&
		\multicolumn{4}{ c |}{\textbf{60k}}		
		\\
		
		\rowcolor{tud9c!50}
		\multirow{-2}{*}{
			\cellcolor{tud9c!70}\textbf{Embedding}}	&
		\multirow{-2}{*}{
			\cellcolor{tud9c!70}\textbf{Dim.}}			&
		\textbf{imbal.}								&
		\textbf{R}									&
		\textbf{bal.}									&
		\textbf{R}									&
		\textbf{imbal.}								&
		\textbf{R}									&
		\textbf{bal.}									&
		\textbf{R}									&
		\textbf{imbal.}								&
		\textbf{R}									&
		\textbf{bal.}									&
		\textbf{R}									
		\\ \hline\hline
		\rowcolor{tud9c!30}
		\multicolumn{14}{| c |}{\textbf{Neural network with hidden layer (\texttt{NN\_H})}}
		\\ \hline
		Vanilla average	& 300 	& 0.58 & 8 	& 0.79 & 8  	& 0.75 & 7 	& 0.88 & 6 	& 0.81 & 5 	& 0.90 & 7 	
		\\ \hline
		p-Means 		& 1,500 	& 0.60 & 6 	& 0.80 & 7  	& 0.76 & 5 	& 0.88 & 6 	& 0.82 & 4		& 0.91 & 5 	
		\\ \hline
		\gls{sif} 		& 300	& 0.59 & 7 	& 0.83 & 6  	& 0.76 & 5 	& 0.90 & 5 	& 0.81 & 5		& 0.91 & 5	
		\\ \hline
		\gls{gem} 		& 300 	& 0.68 & 5		& 0.85 & 5 	& 0.74 & 8 	& 0.86 & 8 	& 0.78 & 8		& 0.87 & 9 	
		\\ \hline
		hier. pooling	& 300	& 0.34 & 12 	& 0.63 & 11 	& 0.48 & 12 	& 0.71 & 11	& 0.52 & 12	& 0.74 & 11
		\\ \hline
		BOREP 		& 4,096	& 0.49 & 9		& 0.74 & 9		& 0.62 & 10	 & 0.82 & 10	& 0.67 & 10	& 0.85 & 10
		\\ \hline
		Random BiLSTM & 8,129	& 0.48 & 11	& 0.71 & 10	& 0.67 & 9		& 0.84 & 9		& 0.75 & 9		& 0.89 & 8
		\\ \hline
		InferSent		& 4,096	& 0.89 & 1		& 0.96 & 2		& 0.95 & 1 	& 0.98 & 2		& 0.98 & 1		& 0.99 & 1 	
		\\ \hline
		Quick-Thought	& 2,400	& 0.80 & 3		& 0.86 & 4		& 0.88 & 3 	& 0.91 & 4		& 0.91 & 3		& 0.93 & 4 	
		\\ \hline
		sent2vec		& 700	& 0.76 & 4 	& 0.98 & 1 	& 0.79 & 4 	& 0.99 & 1 	& 0.81 & 5		& 0.99 & 1	
		\\ \hline
		BERT			& 768	& 0.49 & 9 	& 0.54 & 12 	& 0.54 & 11 	& 0.58 & 12 	& 0.57 & 11	& 0.61 & 12	
		\\ \hline
		LASER		& 1,024	& 0.81 & 2 	& 0.90 & 3		& 0.90 & 2		& 0.93 & 3 	& 0.92 & 2		& 0.94 & 3	
		\\ \hline\hline
		\rowcolor{tud9c!30}
		\multicolumn{14}{| c |}{\textbf{Neural net without hidden layer (\texttt{NN})}}
		\\ \hline
		Vanilla average 		& 300 	& 0.54 & 8 	& 0.75 & 8 	& 0.72 & 8 	& 0.84 & 8		& 0.78 & 8 	& 0.88 & 8 	
		\\ \hline
		p-Means 			& 1,500 	& 0.56 & 7 	& 0.77 & 7		& 0.73 & 7 	& 0.86 & 7 	& 0.80 & 6 	& 0.90 & 5	
		\\ \hline
		\gls{sif} 			& 300	& 0.57 & 6		& 0.82 & 5		& 0.75 & 6 	& 0.88 & 5		& 0.79 & 7 	& 0.90 & 5	
		\\ \hline
		\gls{gem} 			& 300 	& 0.72 & 4		& 0.86 & 3 	& 0.78 & 5 	& 0.88 & 5		& 0.81 & 5 	& 0.90 & 5	
		\\ \hline
		hier. pooling		& 300	& 0.32 & 12	& 0.59 & 11	& 0.47 & 12	& 0.69 & 11	& 0.51 & 12 	& 0.73 & 11	
		\\ \hline
		BOREP 			& 4,096	& 0.46 & 10	& 0.73 & 9		& 0.59 & 9	 	& 0.80 & 9		& 0.66 & 10	& 0.85 & 9
		\\ \hline
		Random BiLSTM 	& 8,129	& 0.40 & 11	& 0.63 & 10	& 0.59 & 9		& 0.77 & 10	& 0.68 & 9		& 0.83 & 10
		\\ \hline
		InferSent			& 4,096	& 0.87 & 1		& 0.94 & 2		& 0.94 & 1 	& 0.98 & 2		& 0.97 & 1 	& 0.99 & 1 	
		\\ \hline
		Quick-Thought		& 2,400	& 0.81 & 2		& 0.84 & 4		& 0.87 & 2 	& 0.91 & 3 	& 0.92 & 2 	& 0.93 & 3
		\\ \hline
		sent2vec			& 700	& 0.79 & 3		& 0.98 & 1 	& 0.80 & 4 	& 0.99 & 1		& 0.82 & 4 	& 0.99 & 1	
		\\ \hline
		BERT				& 768	& 0.48 & 9		& 0.56 & 12	& 0.58 & 11 	& 0.61 & 12	& 0.59 & 11 	& 0.63 & 12	
		\\ \hline
		LASER			& 1,024	& 0.65 & 5		& 0.82 & 5		& 0.86 & 3		& 0.91 & 3		& 0.91 & 3		& 0.93 & 3	
		\\ \hline
	\end{tabularx}}
	\caption[Effects of class (im-)balance as well as data set size on the \caps{WC} probing task results (F1 scores)]
		{Effects of class (im-)balance as well as data set size on the results for the \caps{WC} probing task (F1 scores). The results are
		reported for the \texttt{NN\_H} classifier (top) as well as for the \texttt{NN} classifier (bottom).}
	\label{tab:wc_detail}
\end{table}