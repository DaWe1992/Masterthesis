Längst haben Sentence Embeddings im Forschungsgebiet des Natural Language Processings (NLP) Einzug gehalten. Trotz der überwältigenden Vielzahl an Algorithmen in diesem Bereich ist erstaunlich wenig darüber bekannt, welche Aspekte von Sätzen durch solche Embeddings repräsentiert werden. In den vergangenen Jahren flossen einige Anstrengungen in die Evaluierung vektorieller Repräsentationen von Sätzen, dies jedoch meist ausschließlich für die Englische Sprache. Leider werden andere Sprachen nur selten betrachtet und dann vor allem solche, für die ausreichend Ressourcen zur Verfügung stehen. Beispiele hierfür sind Deutsch, Französisch oder Spanisch. Sprachen, für die derartig viele Ressourcen nicht vorhanden sind, werden zumeist vernachlässigt. Dieser Umstand motiviert dazu, solche Sprachen verstärkt in den Fokus der Forschung zu rücken. Analysen können Aufschluss darüber geben, ob Muster, die für die Englische Sprache entdeckt wurden, auch für andere Sprachen gelten, oder, ob sich die Ergebnisse gänzlich anders darbieten. Die vorliegende Arbeit bedient sich des Konzepts sogenannter \textit{Probing Tasks}, deren Benutzung vor allem von \citep{Conneau.2018a} vorangetrieben wurde. In diesem Zusammenhang wird diese Form der Evaluierung auf mehrere Sprachen erweitert: Englisch, Deutsch, Russisch, Türkisch und Georgisch. Hierbei werden sieben solcher Klassifikationsprobleme für Georgisch implementiert und neun für die restlichen vier Sprachen. Zusätzlich hierzu werden die Embeddings auf drei sogenannten \textit{Downstream Applikationen} getestet. Die Ergebnisse in diesen beiden verschiedenartigen Aufgabentypen werden nachfolgend korreliert. Die Korrelationsanalyse deckt auf, inwiefern sich das Abschneiden von Embeddings in Downstream Applikationen anhand der Ergebnisse auf den Probing Tasks vorhersagen lässt. Wie sich herausstellt, sind die Korrelationen sprachabhängig, wobei die Ergebnisse in anderen Sprachen teils stark von denen in Englisch abweichen.

Der Aufbau der Experimente im Rahmen dieser Arbeit erzeugte Ergebnisse, die zum Teil nicht mit denen aus der Literatur übereinstimmen. Dies gab Anlass dazu, eine zusätzliche Stabilitätsanalyse durchzuführen. Die Ergebnisse dieser Analyse legen nahe, dass die Benutzung großer und balancierter Datensätze von Vorteil ist. Für die Evaluierung wird deshalb empfohlen, Datensätze zu verwenden, die über mindestens 30k Instanzen verfügen, da die Rangfolge der Embeddings bei Datensätzen dieser Größenordnung deutlich stabiler wird. Der Effekt der Optimierung von Hyperparametern kann demgegenüber als vernachlässigbar eingestuft werden, nichtsdestotrotz ist für gewöhnlich ein leicht positiver Einfluss erkennbar. Die Evaluierung im Rahmen dieser Arbeit wird hauptsächlich auf Datensätzen der Größe 10k durchgeführt, die darüber hinaus teils unbalanciert sind. Aus diesem Grund haben die Ergebnisse dieser Arbeit vorläufigen Charakter und sollten weiter validiert werden. Für zukünftige Forschung in diesem Gebiet ist es daher ratsam, die oben gegebenen Empfehlungen zu berücksichtigen.