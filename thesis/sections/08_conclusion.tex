% =======================
% Chapter: Conclusion
%
% Author: Daniel Wehner
%

% Conclusion
% -----------------------------------------------------------------------------------------------------------------------------------------------------
\section{Conclusion}
\label{sec:conclusion}

The goal of the present thesis was focused towards the interpretability of sentence representations in low-resource languages. \textbf{A review of the current literature concerning the evaluation of sentence embeddings showed that the analyses in this domain are mainly done for English and other high-resource languages, very often omitting low-resource languages entirely. This is why the main goal of this work was to extend the probing task setting to lower-resource languages in order to investigate whether findings reported for the English language are reproducible for languages with less resources.} Next to English and German, we chose to include the low-resource languages Russian, Turkish and Georgian. The following paragraphs summarize the main aspects of the thesis:

\highlight{Structure of the thesis.} Section \vref{sec:introduction} first of all gave a short introduction into the topic of this thesis and introduced the research questions which are addressed in the context of this work. The subsequent section \vref{sec:rel_work} demonstrated which efforts have already been made with respect to the development of word and sentence embedding algorithms and gave furthermore information about current evaluation methodologies which are leveraged for the interpretation of what aspects of sentences are retained by sentence embeddings. Sections \vref{sec:word_embs} and \vref{sec:sent_embs} then introduced some of the word and sentence embedding algorithms in depth which were used in the subsequent evaluations. As a next step, section \vref{sec:probing_tasks} presented the notion of probing tasks as well as a list of tasks already introduced in the literature. \textbf{These tasks are generally divided into three categories: tasks probing for superficial, syntactical or semantic aspects of sentences}. In order to facilitate the selection of specific probing tasks for the low-resource target languages, a short presentation of Russian, Turkish and Georgian was given with respect to their grammatical idiosyncrasies. This was necessary, since some linguistic properties may not be present in some of the languages, rendering probing for such properties useless (e.\,g. recall that there are no articles in the Turkish language). After we had made a choice for a set of probing tasks, we provided more information about the process of data set creation and presented which corpora we used as a data source. \textit{\gls{ud}} offers tree banks for many languages covering diversified styles of writing, which is why we chose them for the task at hand. For Georgian it was necessary to resort to the \textit{\gls{gnc}} corpus, since no \textit{\gls{ud}} corpus exists (but soon will). Analogously, chapter \vref{sec:downstream_applications} presented the three downstream applications: Argumentation mining, sentiment analysis and question type detection. Finally, chapter \vref{sec:results_eval} introduced the evaluation results obtained on the probing and downstream tasks. Additionally, the results of the stability analysis were discussed and recommendations for future work were given. The main results are as follows:

\highlight{Main results.} The results indicate that \textbf{trained architectures have advantages over compositional models in high-resource languages in terms of absolute performance}. In low-resource languages, however, compositional models catch up and sometimes manage to outperform their trained counterparts. Nevertheless, the top-three analysis reveals that trained architectures can still be advantageous in low-resource languages. Random encoders furthermore surprise with unexpected high evaluation scores. The correlations computed between probing and downstream task performances were found to be unstable across different languages. Compared to English, we found more correlations falling below an absolute value of 0.20 in German, Russian, Turkish and Georgian. Many correlations even fell into the negative range, where especially the Georgian \caps{WO} task is concerned (due to flexible word order). Since a comparison of our results with the literature revealed inconsistencies in the evaluation setups, we performed an additional stability analysis to investigate the origins of these divergences. Several scenarios (e.\,g. balanced $\leftrightarrow$ imbalanced data sets, hyper-parameter tuning $\leftrightarrow$ no hyper-parameter tuning, etc.) were tested and the performance of the embeddings was recorded. This way it was possible to determine which factors have the strongest influence on the performance of the embeddings and hence on their relative ordering. \textbf{The overall results of this analysis suggest that the findings reported in earlier sections have to be treated with caution}, since we found that data sets with less than 30k training instances induce a rather unstable embedding ordering, while the rankings do not change substantially with more than 30k instances. Furthermore, balanced data sets led to large improvements, especially among the compositional models. Hyper-parameter tuning, on the other hand, did not yield substantially different results and improved the performances only slightly.

\highlight{Future work.} Future research on the evaluation of sentence embeddings in low-resource languages should follow the recommendations we gave in the previous section. The usage of larger (at least 30k instances) and balanced data sets is necessary to get more reliable results. Furthermore, we recommend to use the \textit{SentEval} framework for future experiments. The stability analysis made above all clear that the results vary substantially in different setups. \textbf{We posit that factors like data set \texttt{size} and \texttt{class balance} should have no influence on the evaluation results. The results lead us to believe that the evaluation on probing tasks is not the optimal strategy. Hopefully, additional research can bring more clarity on that. Also we hope that future work will put lower-resource languages more in focus. As some of the results show, patterns for the English language are not necessarily generalizable to other languages.} Finally, we release our implementation for future experiments: \url{https://git.ukp.informatik.tu-darmstadt.de/UKP-Students/interpretability_sentence_embeddings}